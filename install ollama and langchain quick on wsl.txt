# Last amended: 7th June, 2024
# Quick install of WSL ubuntu, ollama and langchain
# For detailed install instructions, refer this file in GitHub:
#	https://github.com/harnalashok/LLMs/blob/main/install%20ollama%20and%20anythingLLM%20on%20ubuntu.txt

# ollama and langchain installation



######################################################
############### AA.1 INSTALL latest wsl Ubuntu #######
######################################################

1.0 Open powershell as Administrator. Write the command:

	wsl --install
	
# 1.0.1 Reboot Windows when asked for. 
#	Create your userid and password in Ubuntu
#	Recommended for office machines: ashok/ashok 


1.1  Update ubuntu and install some needed software:

$ sudo apt update
$ sudo apt install -y net-tools gcc curl git-all gcc g+ build-essential 


# 1.2 Access, folders in wsl by opening in Windows the file-explorer 
#     window and writing address as:

	\\wsl$




######################################################
############### AA.2 INSTALL ollama ##################
######################################################
# 2.0 Install/Uninstall Ollama by following instructions here:
#     See https://github.com/ollama/ollama/blob/main/docs/linux.md:
#	   ollama port: 11434
#


	$ curl -fsSL https://ollama.com/install.sh | sh


# 2.0.1 Issue following commands to download llama3:
#        Downloaded models are saved to folder /usr/share/ollama/.ollama/models

	$ ollama pull llama3:8b   # 5gb
                                  # Alternatives:
	                                  # phi3 is 2.4gb
	                                  # With phi3, ask the question:
	                                    #  You are an expert in machine learning using python language. Write a program to classify species in iris dataset.
	                                  
	                                  # ELSE, tinydolphin is 500mb. Or tinyllama almost the same size
	                                    # BUT, tinydolphin does not know machine-learning. 
                                            # YET tinyllama does know python and machine-learning


# 2.0.2 On terminal, write a question to get an answer.
#       Exit by typing:  /bye


# 2.0.3 ollama supports GPUs with compute capability of 5.


# 2.0.4 List all models downloaded:

	$ ollama list

#	OR 

	$ ollama



# 2.0.5 ollama service can be started/restarted/shut, as:

#	sudo systemctl start/stop ollama




#######################################################
############### AA.3 INSTALL Python environment #######
#######################################################


# 3.0 In Ubuntu, download and Install Anaconda, if not installed

#    a. Download:  
	$ wget -c https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh

#    b. Install:
        $ bash Anaconda3-2024.02-1-Linux-x86_64.sh


# 3.1 Close Ubuntu terminal and then open Ubuntu terminal again

# 3.0.1  Create a folder Documents:

		$ mkdir -p /home/ashok/Documents


# 3.2 Create python environment with conda and install packages
#       Copy and paste all the following conda and pip commands
#	in ubuntu (wsl) terminal in one go (copy and paste):

# FOR GPU equipped machines:

conda create -y --name langchain python=3.11
conda activate langchain
conda config --add channels conda-forge
conda config --add channels huggingface
conda install -y -c pytorch faiss-gpu
conda install -y spyder jupyter jupyterlab pandas numpy pip-tools ipython langchain beautifulsoup4 pypdf transformers fastai::accelerate huggingface_hub git openai streamlit
conda install -y datasets
pip install ollama chromadb langchain-experimental tensorflow sacremoses sentencepiece  
pip install --upgrade   llama-cpp-python tf-keras

# FOR CPU only machines. No GPU:

conda create -y --name langchain python=3.11
conda activate langchain
conda config --add channels conda-forge
conda config --add channels huggingface
conda install -y -c pytorch faiss-cpu
conda install -y spyder jupyter jupyterlab pandas numpy pip-tools ipython langchain beautifulsoup4 pypdf transformers fastai::accelerate huggingface_hub git openai streamlit
conda install -y datasets
pip install ollama chromadb langchain-experimental tensorflow sacremoses sentencepiece  
pip install --upgrade   llama-cpp-python tf-keras



######################################################
############### If you have GPU ######################
############### AA.4 INSTALL CUDA ####################
############# AND Appropriate driver #################

######################################################


# 4.0 Install CUDA. Installation depends upon
#   	which GPU is available. For GPU 1060 or 730 install
#	 CUDA 11.4
#      Refer my github notebook and the paragraph: 
#		"Which driver and which CUDA version for your nvidia gpu card"
#	    		https://github.com/harnalashok/LLMs/blob/main/gpu_nvidia.ipynb



#######################################################
############### AA.5 Starting chromdb server #######
#######################################################


# 5.0 If required, you can start chromadb. In Ubuntu issue the 
#     following two commands. After the commands are issued, 
#      keep ubuntu terminal open:


		$ conda activate langchain
                $ mkdir /home/ashok/Documents/chroma
		$ chroma run --path /home/ashok/Documents/chroma

#		  Keep the ubuntu terminal open.

#     In the browser, access: http://localhost:8000

#############################################

###################################
## chromadb as an ubuntu service ##
###################################
# Ref:  https://cookbook.chromadb.dev/running/systemd-service/#chroma-cli

$ mkdir -p /home/ashok/Documents/data



# Run the following command to open a file:

$ sudo tilde /etc/systemd/system/chroma.service

# and then copy/paste the following lines
# save the file and exit:
#*********************************


[Unit]
Description = Chroma Service
After = network.target

[Service]
Type = simple
User = root
Group = root
WorkingDirectory = /home/ashok/Documents
ExecStart=/home/ashok/anaconda3/envs/langchain/bin/chroma run --host 127.0.0.1 --port 8000 --path /home/ashok/Documents/data --log-path /var/log/chroma.log

[Install]
WantedBy = multi-user.target

#*********************************


------------------------
6.0 System Prompt Examples:
-------------------------

	The system prompt can effectively provide your chat bot specialized roles,
	and results tailored to the prompt you have given the model. Examples of 
	system prompts can be found here: ChatGPT-3.5 Roles:
	https://www.w3schools.com/gen_ai/chatgpt-3-5/chatgpt-3-5_roles.php

	Some interesting examples to try include:

    		You are -X-. You have all the knowledge and personality of -X-. Answer
    		as if you were -X- using their manner of speaking and vocabulary.
        
        	Example: You are Shakespeare. You have all the knowledge and personality
        		 of Shakespeare. Answer as if you were Shakespeare using their manner
        		 of speaking and vocabulary.

			You are an expert (at) -role-. Answer all questions using your expertise
			on -specific domain topic-.

        	Example: You are an expert software engineer. Answer all questions using your 
        		 expertise on Python.

			You are a -role- bot, respond with -response criteria needed-. If 
			no -response criteria- is needed, respond with -alternate response-.
			
        	Example: You are a grammar checking bot, respond with any grammatical corrections
        		 needed. If no corrections are needed, respond with “verified”.
        		 
 	 
        		 


############ DONE ################

# Syntax to remove conda env -- myenv

        conda remove -y --name langchain --all

############ DONE ################
