{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d27ba4-877f-436f-ae15-768b577d16bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last amended: 23rd April, 2024\n",
    "# perplexity.ai question:\n",
    "#   how to use langchain with huggingface pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6228ccc6-0d97-40c8-955a-9c56d1c779d1",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "Using ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92011e1-1300-47d9-a73b-32fdd8a6fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume ollama is started on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597d6c90-d57b-4ebb-ae43-0ca17de839e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.0\n",
    "from langchain_community.llms import Ollama\n",
    "# 1.0.1\n",
    "llm = Ollama(model=\"llama2\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba60a6b-34c3-48cd-b541-fc4abdf490ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool that can be used for testing purposes in several ways:\n",
      "\n",
      "1. **Automated Testing**: Langsmith provides a built-in test framework that allows you to write and run automated tests for your code. You can use this framework to test your code's functionality, performance, and security.\n",
      "2. **Code Review**: Langsmith's syntax highlighting and code completion features can help you identify potential issues in your code during the review process. For example, it can highlight syntax errors or suggest better coding practices.\n",
      "3. **Debugging**: Langsmith's debugging features can help you identify and fix runtime errors in your code. You can use the debugger to step through your code line by line, examine variables, and set breakpoints.\n",
      "4. **Code Refactoring**: Langsmith's refactoring tools can help you improve the structure and organization of your code. For example, it can automatically extract functions, move code around, or rename variables.\n",
      "5. **Security Testing**: Langsmith provides a security testing feature that allows you to identify potential security vulnerabilities in your code. It can check for common security flaws such as SQL injection, cross-site scripting, and input validation issues.\n",
      "6. **Performance Optimization**: Langsmith's performance optimization features can help you identify bottlenecks in your code and optimize it for better performance. You can use the profiler to identify slow code segments and optimize them using various techniques such as caching, parallel processing, or algorithm improvements.\n",
      "7. **Collaboration**: Langsmith allows multiple developers to work together on a project, making it easier to collaborate and manage code changes. You can use the version control system to track changes, roll back to previous versions if necessary, and collaborate with other developers in real-time.\n",
      "8. **Documentation**: Langsmith provides documentation tools that allow you to create and maintain documentation for your code. You can use the documentation generator to create HTML documentation, user manuals, or technical guides for your code.\n",
      "9. **Code Analysis**: Langsmith's code analysis features can help you identify potential issues in your code such as coding standards violations, unused variables, and redundant code. You can use these features to improve the quality of your code and make it more maintainable.\n",
      "10. **Learning Resources**: Langsmith provides a range of learning resources such as tutorials, documentation, and sample projects that can help you learn new programming concepts and improve your coding skills.\n",
      "\n",
      "Overall, Langsmith can help you with testing in various ways, from automated testing to code review, debugging, and security testing. It also provides features for collaboration, documentation, code analysis, and learning resources to help you improve the quality of your code and make it more maintainable.\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Ask llama2 a question:\n",
    "\n",
    "output = llm.invoke(\"how can langsmith help with testing?\")\n",
    "\n",
    "# 1.1.1\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bda255-da6c-4f54-a4b9-7916c7f83093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 2.1\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "                                            [\n",
    "                                               (\"system\", \"You are world class technical documentation writer.\"),\n",
    "                                               (\"user\", \"{input}\")   # {input} is a placeholder for message\n",
    "                                            ]\n",
    "                                        )\n",
    "# 2.2\n",
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d4579a-80d7-4769-868e-09e2a41062b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAs a world-class technical documentation writer, I must say that LingSmith is an incredible tool for automating the testing process. Here are some ways in which LangSmith can help with testing:\\n\\n1. Automated Testing: LangSmith's AI-powered engine can automatically generate test cases based on your codebase, reducing the time and effort required to write tests manually. This helps ensure that all aspects of your software are thoroughly tested, including corners cases and edge scenarios.\\n2. Code Coverage Analysis: LangSmith can analyze your code coverage to identify areas that are not being tested enough or at all. This helps you prioritize your testing efforts on the most critical parts of your codebase, ensuring that no bugs or issues are overlooked.\\n3. Test Data Generation: LangSmith's AI engine can generate test data automatically, based on your input parameters and constraints. This saves time and effort in creating test data manually and helps ensure that your tests are comprehensive and cover a wide range of scenarios.\\n4. Defect Prediction: LangSmith's advanced algorithms can predict potential defects in your codebase before they occur, helping you address issues proactively rather than reactively. This leads to higher quality software with fewer bugs and errors.\\n5. Continuous Integration/Continuous Deployment (CI/CD): LangSmith can integrate seamlessly with your CI/CD pipeline, automating the testing process at every stage of your development workflow. This ensures that your software is thoroughly tested and validated before it reaches end-users.\\n6. Customizable Reporting: LangSmith provides customizable reporting options to suit your needs. You can generate reports on code coverage, test effectiveness, defect prediction, and other critical metrics. These reports help you measure the success of your testing efforts and identify areas for improvement.\\n7. Integration with Existing Tools: LangSmith integrates seamlessly with a wide range of tools and platforms, including JIRA, Jenkins, Travis CI, CircleCI, and more. This ensures that you can leverage the full potential of LangSmith without disrupting your existing workflows or toolchain.\\n\\nIn summary, LangSmith is an incredibly powerful tool for automating the testing process. By leveraging AI-powered test generation, code coverage analysis, test data generation, defect prediction, and integration with popular development tools, LangSmith can help you deliver higher quality software faster and more efficiently.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.3\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79f71b-741c-4709-94ec-4a1fd62f47fe",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "Using huggingface pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5d6f21-4bf0-4084-b59e-56c6d950bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.0\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fe6b2d-533c-4855-8bdc-a55fe933c8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb22bf6be9842cf909d3e7e9b0788ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af56b20854e64521929310ac0891b97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002a105e49444aecaf8c6a5cdae380f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72e71fa1c2e4d5da44e9f8de48ce4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f1326aaf9a413ba18f24c05386ae47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5432b34df7084653b7e4e7c3deac7614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe11f37db4e4724a2bd80215c238382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'If it is sunny today then \\xa0it will be cloudy tomorrow.\\nI have been using this for a while now and I am very happy with it. I have been using it for a while now and I am very happy with it. I'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1\n",
    "text_generator = pipeline(model=\"gpt2\")\n",
    "\n",
    "# 3.1.1\n",
    "text_generator(\"If it is sunny today then \", do_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffca174-214e-410d-b247-6ead2a0b0c33",
   "metadata": {},
   "source": [
    "## Method 3\n",
    "\n",
    "Using langchain and huggingface pipeline    \n",
    "The following code is from <b> [perplexity.ai](https://www.perplexity.ai/)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3116c31-3b64-434e-8403-e24dea9fd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0\n",
    "from langcahain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "# 4.1\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246ce794-129c-4f9b-abf2-bbf61def679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1\n",
    "model_id = \"gpt2\"  # or any other model ID\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0668c10c-5858-4ca5-a632-043386d1d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2\n",
    "pipe = pipeline(\n",
    "                 \"text-generation\",\n",
    "                  model=model,\n",
    "                  tokenizer=tokenizer,\n",
    "                  max_new_tokens=10\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44c6618-d84e-4b26-887a-3c4eba7be280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e3bf63b-fef9-4aee-9afb-a7585a5ca4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography? Answer: Let's think step by step. Electroencephalography is the use of digital imagery\n"
     ]
    }
   ],
   "source": [
    "# 4.4\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question} Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | hf\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "print(chain.invoke({\"question\": question}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe09c72-2c04-4b07-a0a5-b2802cd5ad54",
   "metadata": {},
   "source": [
    "Another way to specify model without creating a pipeline first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892af34a-c344-4971-b75b-82652c4adb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "                                        model_id=\"gpt2\",\n",
    "                                        task=\"text-generation\",\n",
    "                                        pipeline_kwargs={\"max_new_tokens\": 10},\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b009f5-93db-4796-9af8-26c050ebf25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography? Answer: Let's think step by step. First we'll look at the brainwaves that are\n"
     ]
    }
   ],
   "source": [
    "# 5.1\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 5.2\n",
    "template = \"\"\"Question: {question} Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | hf\n",
    "\n",
    "# 5.3\n",
    "question = \"What is electroencephalography?\"\n",
    "print(chain.invoke({\"question\": question}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce395b4-e8bc-497d-b2ea-0276da44f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DONE #############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
