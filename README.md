# LLMs
## loginto huggingface howto
See [this notebook](https://github.com/harnalashok/LLMs/blob/main/loginto%20huggingface%20howto.ipynb)


## [Basics of LLMS_I](https://github.com/harnalashok/LLMs/blob/main/Basics%20of%20LLMs_I.ipynb)
>1. Note on LLMS
>2. LLM use cases
>3. Proprietary services
>4. Open source models
>5. Sentence transformers
>6. Smeantic Search
>7. Approx nearest neighbour search
>8. Retireve and Re-rank
>9. Retieval: Bi-Encoder
>10.Re-Ranker: Cross-Encoder
>11. How FAISS works
>12. What is vector store?
>13. How are vector databases used?
>14. What are the benefits of vector databases?
>15. What is LLM Prompter?
>16. What is quantization?
>17. Why GGUF format?
>18. Complete chatbot cycle?
>Notebooks and other material on LLMs

## [Basics of LLMs_II](https://github.com/harnalashok/LLMs/blob/main/Basics%20of%20LLMs_II.ipynb)
>1. NLP Moore's Law
>2. Resources
>3. Prompt Engineering
> > Six strategies for getting better results   
>> Chain of thought   
>> Example of complete prompt   
>>What is Zero-Shot Chain-of-Thought prompting?
 
>4.Prompts for general coding workflows      
>5.What is RAG
>>What is the difference between Retrieval-Augmented Generation and semantic search?

## [Basics of LLMs__III](https://colab.research.google.com/github/harnalashok/LLMs/blob/main/Basics_of_LLMs_III.ipynb#scrollTo=7H5Psi9BbuaS)
>1.A list/collection of open source and/or local AI tools and solutions.    
>2.Byte Pair Encoding    
>3.What is Ollama?    
>> Models supported by ollama. See [List here](https://ollama.com/library)<br>
>> Create custom ollama models by using [Modelfile](https://github.com/ollama/ollama/blob/main/docs/modelfile.md#basic-modelfile) and also see [this Modelfile](https://github.com/harnalashok/LLMs/blob/main/Modelfile) on github<br>
>> Ollama based [webUIs](https://github.com/ollama/ollama/tree/main?tab=readme-ov-file#web--desktop)<br>    
>> Where are ollama models stored?
 
>4.What is ollama-index    
>> Why LlamaIndex for Context Augmentation?

>5.Nomic Text Embeddings
>6.How are LLM models named   
>7.Types of LLM models
>>Uncensored models--[What are they?](https://erichartford.com/uncensored-models) with [examples](https://ollama.com/blog/run-llama2-uncensored-locally)

## [Basics of LLMs_IV](https://github.com/harnalashok/LLMs/blob/main/Basics_of_LLMs_IV.ipynb)
>>Why self-supervised learning   
>>>Distortion    
>>>Rotation    
>>>Patches<br>

>2.langchain   
>>Why is langchain important?
>>langchain use cases with example code  
>>How does langchain work?    
>>What are core components of langchain?<br>
>>LLM Parameters (temperature, top-k etc)

## [Quickstart langchain](https://github.com/harnalashok/LLMs/blob/main/Quickstart%20langchain.ipynb)
langchain QuickStart   
>langchain API Reference
>langchain video lectures     
>langchain simple tutorials    
>Broad steps for RAG    
>How is langchain organized    
>Installation    
Wrining Prompts       
>How to create a prompt       
Chains in langchain       
>LLM Chain       
>Sequential Chain       
>Retrieval chain       
Getting data from the Web       
FAISS       
Generate Answers to Questions using LLM       
Conversational Retrieval Chain       
Reading pdf files:
> from disk
> from folder/directory
## Simple RAG for GitHub issues using Hugging Face Zephyr and LangChain [Link](https://github.com/harnalashok/LLMs/blob/main/RAG_on_Colab_with_Huggingface_and_langchain.ipynb)
What is a RAG     
RAG on Colab using Huggingface models and langchain     
Creating and using Quantized models     
Using FAISS library     
Design prompt template     
HuggingFace pipeline and langchain pipeline wrapper     


      


    


