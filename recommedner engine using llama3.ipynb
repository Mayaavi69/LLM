{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93fcda08-3386-4ecc-a10f-60ef6608e7ac",
   "metadata": {},
   "source": [
    "Reference this [article](https://medium.com/data-science-in-your-pocket/recommendation-systems-using-langchain-and-llms-with-codes-d3c4c4e66732)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4f3c76-0b9b-4640-ae57-1987df416150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fee4e56-33a5-4508-b42c-36233c975a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id\n",
      "0      355       15\n",
      "1      787        2\n",
      "2      651       13\n",
      "3      119       15\n",
      "4      129       19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the number of users and unique items\n",
    "num_users = 1000\n",
    "num_items = 20\n",
    "\n",
    "# Generate random user IDs and item IDs\n",
    "user_ids = np.arange(1, num_users + 1)\n",
    "item_ids = np.arange(1, num_items + 1)\n",
    "\n",
    "# Create random interaction data\n",
    "data = {\n",
    "    'user_id': np.random.choice(user_ids, size=num_users * 10),\n",
    "    'item_id': np.random.choice(item_ids, size=num_users * 10),\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame from the data\n",
    "df = pd.DataFrame(data).drop_duplicates()\n",
    "\n",
    "# Display the first few rows of the generated data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a93e8a-3c67-456c-a2c8-383fd0e903cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping all interactions by a user as list\n",
    "df = df.groupby(['user_id'])['item_id'].agg(list).reset_index()\n",
    "\n",
    "#creating OHE \n",
    "df['item_id'] = df['item_id'].transform(lambda x: [0 if y+1 not in x else y+1 for y in range(20)])\n",
    "\n",
    "#save csv\n",
    "df.to_csv('dummy_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b9119d-df25-4f63-8418-abafb627fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1d7722-d0cb-4dce-b110-d945fb0535f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ollama(model='llama3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aca4a45c-889d-426a-b6a6-105e6e32a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pritning markdown text\n",
    "# StackOverflow: https://stackoverflow.com/a/32035217\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591b5beb-3d84-498a-90e0-56daf89c6736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Langsmith, as a language model, can be used in various ways to assist with testing:\n",
       "\n",
       "1. **Automated Testing**: Langsmith can generate test data and scenarios for automated testing frameworks like Selenium or Cypress. This saves developers time and reduces the need for manual testing.\n",
       "2. **Test Data Generation**: Langsmith can create realistic test data (e.g., user input, product descriptions) to help populate test cases. This ensures that tests cover a wide range of scenarios and edge cases.\n",
       "3. **Natural Language Processing (NLP) Testing**: Langsmith's NLP capabilities can be used to test the accuracy of natural language processing models, such as text classification, sentiment analysis, or named entity recognition.\n",
       "4. **Error Message Generation**: Langsmith can generate error messages that mimic real-world scenarios, helping developers test error handling and recovery mechanisms in their code.\n",
       "5. **Test Case Development**: Langsmith's ability to generate text based on prompts can be used to develop test cases for software applications. For example, generating test cases for a chatbot or virtual assistant.\n",
       "6. **Code Review**: Langsmith can help with code review by analyzing code snippets and providing feedback on syntax, semantics, and best practices, helping developers catch errors and improve their code quality.\n",
       "\n",
       "To get started with using Langsmith for testing, you can:\n",
       "\n",
       "* Use the Langsmith API to integrate it with your testing framework or script.\n",
       "* Generate test data or scenarios using the Langsmith web interface or command-line tool.\n",
       "* Train a custom Langsmith model for specific testing purposes (e.g., generating error messages or test cases).\n",
       "\n",
       "By leveraging Langsmith's language processing capabilities, you can streamline your testing process, reduce errors, and improve code quality."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = llm.invoke(\"how can langsmith help with testing?\")\n",
    "printmd(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492d5a78-9cc4-4b32-930c-a0a8c07e97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "loader = CSVLoader(file_path=\"dummy_data.csv\")\n",
    "data = loader.load()\n",
    "\n",
    "#data transformers\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "#embeddings model, this can be a local LLM as well\n",
    "embeddings = OllamaEmbeddings(model = 'llama3')\n",
    "#Vector DB\n",
    "docsearch = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "#Retriever\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d487a8a7-d978-4b8b-a7e3-560708462777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=Ollama(model='llama3')), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f4e894d1b50>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e3de6d-e49a-410f-8333-a21a07b9df90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"To suggest two articles to user-id 78, I'll follow the approach of finding similar users and suggesting new articles from those similar users\", \"\\n\\nFirst, I'll identify the most frequent item_id values across all users:\\n\\n* [1], [2], [6], [7], [8], [9], [12], [13], [15], [16], and [19] are present in multiple user_id values\", ' These items seem to be popular among users', \"\\n\\nNext, I'll find similar users to user-id 78 by looking for users who have purchased similar items:\\n\\n* User-id 98 has purchased item_id [1], which is also present in the data of user-id 2 and user-id 10\", '\\n* User-id 555 has purchased item_id [6] and [19], both of which are present in the data of user-id 10', \"\\n\\nBased on this analysis, I'll suggest two articles to user-id 78 that have not been seen before:\\n\\n1\", ' Item_id: 14 (reason: Users 98 and 10 have similar tastes, and user-id 98 has not purchased item_id 14)\\n2', ' Item_id: 21 (reason: User-id 555 has similar interests to users 10 and 2, and user-id 555 has not purchased item_id 21)\\n\\nPlease note that this is a simple suggestion algorithm based on the given data, and actual user behavior may be more complex and influenced by many factors', '']\n"
     ]
    }
   ],
   "source": [
    "print(qa.run('Suggest 2 articles to user-id 78 using given data which it has not seen.\\\n",
    "Follow this approach 1: Find similar Users and 2: sugest new articles from similar users.\\\n",
    "Also give a reason for suggestion').split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07ae1c31-7f60-4c06-978d-56ad925dcde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### DONE ####################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
